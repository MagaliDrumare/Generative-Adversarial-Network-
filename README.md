# A voir et à savoir :

#### - Les Generative Adversarial Networks (GANs) sont des algorithmes d'intelligence artificielle 
utilisé dans le machine learning non supervisé (unsupervised machine learning). Ces  ont été inventés en 2014 par Ian Goodfellow. 
* NIPS 2016 Workshop on Adversarial Training:  https://youtu.be/RvgYvHyT15E
* Generative Adversarial Networks Explained with a Classic Spongebob : https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39
* Generative Adversarial Networks (LIVE) : https://www.youtube.com/watch?v=0VPQHbMvGzg (by Siraj Raval)

#### - Un GAN est composé de deux réseau : un Générateur (Generator) et un Discriminateur (Descriminator). 
Le Générateur a comme inputs des données (Independant Gaussian Distribution et génère des images (Deconvolutional network)
Le Discriminateur a comme inputs des images et génère un output VRAI/FAUX (Convolutional network)


#### - Architecture des deux réseaux de neurones 
* Générateur-Deconvolutional Network : génération de moins d'inputs et plus grands à chaque layer. 
![alt tag](https://cdn-images-1.medium.com/max/1600/1*WIhhgBzDQJFcj7CqPvzPdQ.png)

```
def generator(batch_size, z_dim):
algorithmes
	# z = independant gaussian distribution 
    z = tf.truncated_normal([batch_size, z_dim], mean=0, stddev=1, name='z')
    #first deconv block
    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))by 
    g_b1 = tf.get_variable('g_b1', [3136], 
    initializer=tf.truncated_normal_initializer(stddev=0.02))
    g1 = tf.matmul(z, g_w1) + g_b1
    g1 = tf.reshape(g1, [-1, 56, 56, 1])
    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')
    g1 = tf.nn.relu(g1)

    # Generate 50 features
    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], 
    dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b2 = tf.get_variable('g_b2', [z_dim/2], 
    initializer=tf.truncated_normal_initializer(stddev=0.02))
    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')
    g2 = g2 + g_b2
    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')
    g2 = tf.nn.relu(g2)
    g2 = tf.image.resize_images(g2, [56, 56])

    # Generate 25 features
    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], 
    dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b3 = tf.get_variable('g_b3', [z_dim/4], 
    initializer=tf.truncated_normal_initializer(stddev=0.02))
    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')
    g3 = g3 + g_b3
    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')
    g3 = tf.nn.relu(g3)
    g3 = tf.image.resize_images(g3, [56, 56])

    # Final convolution with one output channel = one big image 
    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], 
    dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b4 = tf.get_variable('g_b4', [1], 
    initializer=tf.truncated_normal_initializer(stddev=0.02))
    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')
    g4 = g4 + g_b4
    g4 = tf.sigmoid(g4)

    # No batch normalization at the final layer, but we do add
    # a sigmoid activator to make the generated images crisper.
    # Dimensions of g4: batch_size x 28 x 28 x 1

    return g4

```
* Discriminateur-Convolutional Network : génération de plus d'inputs mais moins grands à chaque layer (voir CNN) 
![alt tag](https://i.stack.imgur.com/keDyv.png)


#### - Implémentation du GAN 

```
sess=tf.Session()
batch_size= 50 # 50 images 
z_dimension = 100 # z can have a lot of dimension

#feed image to D 
x_placeholder =tf.placeholder('float', shape=[None,28,28,1], name='placeholder')

## Networks 
# Generator(z)
Gz = generator(batch_size, z_dimensions)

# Discriminator x_placeholder)-prob of the real image 
Dx= discriminator(x_placeholder)

# Feed the discrimantor with the image generated by the Generator d(g(z))-prob of generated image 
Dg = discriminator(Gz, reuse=True)

```

#### - Les fonctions de coûts des GAN (Loss) 

> Fonction de coût du Discriminateur: 
Une équation de coût en deux parties
- (1)Première partie: les vraies images du "training set" sont reconnues correctement par le discriminateur. 
- (2)Deuxième partie : les fausses images générées par le générateur sont reconnues correctement par le discriminateur.

> Fonction de coût du Générateur : 
- (3)Les fausses images générées par le discriminateur ne sont pas reconnues correctement par le discriminateur.

> L'optimisation du DGAN est un match entre l'optimisation deux networks. Les DGAN ne sont pas faciles à entrainer. 

```
# (3)Generatorloss 
g_loss=tf.reduce_mean(tf.nn.sigmoid_crossentropy_with_logits(logits=Dg,labels=tf.one_like(Dg)))

# Discriminator loss 
#(1)First part 
d_loss_real= tf.reduce_mean(tf.nn.sigmoid_crossentropy_with_logits(logits=Dx,labels=tf.fill([batch_size,1], 0.9)))
#(2)Second part 
d-loss_fake = tf.reduce_mean(tf.nn.sigmoid_crossentropy_with_logits(logits=Dg,labels=tf.zeros_like(Dg)))
d_loss= d_loss_real+d_loss_fake

```








